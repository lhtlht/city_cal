{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train_dataset.csv')\n",
    "test = pd.read_csv('input/test_dataset.csv')\n",
    "test['信用分'] = None\n",
    "train = train.append(test)\n",
    "train.columns = ['id','is_name_real','age','student','blacklist','is_4g_unhealth','internet_age','last_pay_until_now','last_pay_amount','amount_avg_6mon',\n",
    "            'current_check_amount','remaining_amount','is_owe','sensitive','talk_number','shoping_usually','shoping_count','came_wandan','came_shanmu',\n",
    "            'came_movie','came_tour','came_pe','buy_app_usage','logistics_app_usage','finance_app_usage','video_app_usage','air_app_usage',\n",
    "                 'train_app_usage','news_app_usage','grades']\n",
    "raw_df = train[['id','grades']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cross_features.pkl','regular.pkl','lda.pkl']\n",
    "for f in features:\n",
    "    data = pd.read_pickle('features/%s'%f)\n",
    "    for c in data.columns:\n",
    "        raw_df[c] = data[c].tolist()\n",
    "train = raw_df.iloc[0:50000,:]\n",
    "test = raw_df.iloc[50000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = [x for x in train.columns if x not in ['id','grades']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor =  ['is_name_real', 'age', 'student', 'is_4g_unhealth',\n",
    "       'internet_age', 'last_pay_until_now', 'last_pay_amount',\n",
    "       'amount_avg_6mon', 'current_check_amount', 'remaining_amount', 'is_owe',\n",
    "       'sensitive', 'talk_number', 'shoping_usually', 'shoping_count',\n",
    "       'came_wandan', 'came_shanmu', 'came_movie', 'came_tour', 'came_pe',\n",
    "       'buy_app_usage', 'logistics_app_usage', 'finance_app_usage',\n",
    "       'video_app_usage', 'air_app_usage', 'train_app_usage', 'news_app_usage',\n",
    "        'first_online_time', 'consume_change', 'is_enough',\n",
    "       'consume_plan', 'consume_change_plan','last_pay_amount_offline','current_fee_stability', 'use_left_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_sp... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "cv 14.817457\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-14.82   \u001b[0m | \u001b[0m 0.9098  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 3.014   \u001b[0m | \u001b[0m 1.635   \u001b[0m | \u001b[0m 6.114   \u001b[0m | \u001b[0m 34.07   \u001b[0m | \u001b[0m 0.04432 \u001b[0m | \u001b[0m 88.21   \u001b[0m |\n",
      "cv 14.780767\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-14.78   \u001b[0m | \u001b[95m 0.9927  \u001b[0m | \u001b[95m 0.4068  \u001b[0m | \u001b[95m 3.959   \u001b[0m | \u001b[95m 1.587   \u001b[0m | \u001b[95m 6.835   \u001b[0m | \u001b[95m 46.65   \u001b[0m | \u001b[95m 0.008033\u001b[0m | \u001b[95m 30.27   \u001b[0m |\n",
      "cv 14.836806\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-14.84   \u001b[0m | \u001b[0m 0.804   \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.891   \u001b[0m | \u001b[0m 2.61    \u001b[0m | \u001b[0m 8.883   \u001b[0m | \u001b[0m 40.96   \u001b[0m | \u001b[0m 0.04669 \u001b[0m | \u001b[0m 80.2    \u001b[0m |\n",
      "cv 14.836535\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-14.84   \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 2.834   \u001b[0m | \u001b[0m 6.604   \u001b[0m | \u001b[0m 23.66   \u001b[0m | \u001b[0m 0.02719 \u001b[0m | \u001b[0m 79.74   \u001b[0m |\n",
      "cv 14.816456\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-14.82   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 0.5547  \u001b[0m | \u001b[0m 0.09395 \u001b[0m | \u001b[0m 1.853   \u001b[0m | \u001b[0m 7.054   \u001b[0m | \u001b[0m 32.76   \u001b[0m | \u001b[0m 0.09443 \u001b[0m | \u001b[0m 73.09   \u001b[0m |\n",
      "cv 14.788045\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.8719  \u001b[0m | \u001b[0m 0.4496  \u001b[0m | \u001b[0m 3.488   \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 7.327   \u001b[0m | \u001b[0m 35.18   \u001b[0m | \u001b[0m 0.02183 \u001b[0m | \u001b[0m 33.28   \u001b[0m |\n",
      "cv 14.792475\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.8631  \u001b[0m | \u001b[0m 0.391   \u001b[0m | \u001b[0m 2.851   \u001b[0m | \u001b[0m 1.316   \u001b[0m | \u001b[0m 8.932   \u001b[0m | \u001b[0m 9.592   \u001b[0m | \u001b[0m 0.02168 \u001b[0m | \u001b[0m 35.61   \u001b[0m |\n",
      "cv 14.773872\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-14.77   \u001b[0m | \u001b[95m 0.9306  \u001b[0m | \u001b[95m 0.3026  \u001b[0m | \u001b[95m 2.332   \u001b[0m | \u001b[95m 0.7333  \u001b[0m | \u001b[95m 4.793   \u001b[0m | \u001b[95m 9.967   \u001b[0m | \u001b[95m 0.06598 \u001b[0m | \u001b[95m 33.95   \u001b[0m |\n",
      "cv 14.819643\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-14.82   \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.395   \u001b[0m | \u001b[0m 4.105   \u001b[0m | \u001b[0m 0.2913  \u001b[0m | \u001b[0m 8.181   \u001b[0m | \u001b[0m 9.324   \u001b[0m | \u001b[0m 0.09767 \u001b[0m | \u001b[0m 57.74   \u001b[0m |\n",
      "cv 14.781981\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-14.78   \u001b[0m | \u001b[0m 0.9954  \u001b[0m | \u001b[0m 0.5839  \u001b[0m | \u001b[0m 3.696   \u001b[0m | \u001b[0m 0.1176  \u001b[0m | \u001b[0m 5.411   \u001b[0m | \u001b[0m 10.41   \u001b[0m | \u001b[0m 0.03032 \u001b[0m | \u001b[0m 32.55   \u001b[0m |\n",
      "cv 14.801269\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-14.8    \u001b[0m | \u001b[0m 0.8636  \u001b[0m | \u001b[0m 0.4314  \u001b[0m | \u001b[0m 0.3207  \u001b[0m | \u001b[0m 2.077   \u001b[0m | \u001b[0m 6.827   \u001b[0m | \u001b[0m 16.94   \u001b[0m | \u001b[0m 0.0528  \u001b[0m | \u001b[0m 30.76   \u001b[0m |\n",
      "cv 14.800983\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-14.8    \u001b[0m | \u001b[0m 0.9152  \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 1.593   \u001b[0m | \u001b[0m 2.002   \u001b[0m | \u001b[0m 4.658   \u001b[0m | \u001b[0m 37.23   \u001b[0m | \u001b[0m 0.02965 \u001b[0m | \u001b[0m 37.19   \u001b[0m |\n",
      "cv 14.795846\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-14.8    \u001b[0m | \u001b[0m 0.9173  \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 4.145   \u001b[0m | \u001b[0m 0.01409 \u001b[0m | \u001b[0m 7.382   \u001b[0m | \u001b[0m 17.15   \u001b[0m | \u001b[0m 0.07378 \u001b[0m | \u001b[0m 93.28   \u001b[0m |\n",
      "cv 14.785629\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.8498  \u001b[0m | \u001b[0m 0.5609  \u001b[0m | \u001b[0m 2.96    \u001b[0m | \u001b[0m 1.717   \u001b[0m | \u001b[0m 5.113   \u001b[0m | \u001b[0m 47.87   \u001b[0m | \u001b[0m 0.04527 \u001b[0m | \u001b[0m 84.94   \u001b[0m |\n",
      "cv 14.790584\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.9399  \u001b[0m | \u001b[0m 0.3379  \u001b[0m | \u001b[0m 4.069   \u001b[0m | \u001b[0m 1.19    \u001b[0m | \u001b[0m 8.397   \u001b[0m | \u001b[0m 31.16   \u001b[0m | \u001b[0m 0.08829 \u001b[0m | \u001b[0m 73.86   \u001b[0m |\n",
      "cv 14.804038\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-14.8    \u001b[0m | \u001b[0m 0.9451  \u001b[0m | \u001b[0m 0.5011  \u001b[0m | \u001b[0m 4.78    \u001b[0m | \u001b[0m 1.932   \u001b[0m | \u001b[0m 6.115   \u001b[0m | \u001b[0m 32.29   \u001b[0m | \u001b[0m 0.0029  \u001b[0m | \u001b[0m 45.71   \u001b[0m |\n",
      "cv 14.768125\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m-14.77   \u001b[0m | \u001b[95m 0.932   \u001b[0m | \u001b[95m 0.3321  \u001b[0m | \u001b[95m 3.09    \u001b[0m | \u001b[95m 1.286   \u001b[0m | \u001b[95m 4.676   \u001b[0m | \u001b[95m 18.42   \u001b[0m | \u001b[95m 0.05743 \u001b[0m | \u001b[95m 66.54   \u001b[0m |\n",
      "cv 14.834091\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-14.83   \u001b[0m | \u001b[0m 0.9149  \u001b[0m | \u001b[0m 0.6226  \u001b[0m | \u001b[0m 3.261   \u001b[0m | \u001b[0m 1.294   \u001b[0m | \u001b[0m 8.474   \u001b[0m | \u001b[0m 21.54   \u001b[0m | \u001b[0m 0.04415 \u001b[0m | \u001b[0m 88.22   \u001b[0m |\n",
      "cv 14.833434\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-14.83   \u001b[0m | \u001b[0m 0.9612  \u001b[0m | \u001b[0m 0.6631  \u001b[0m | \u001b[0m 0.5011  \u001b[0m | \u001b[0m 2.758   \u001b[0m | \u001b[0m 7.564   \u001b[0m | \u001b[0m 49.95   \u001b[0m | \u001b[0m 0.0158  \u001b[0m | \u001b[0m 86.51   \u001b[0m |\n",
      "cv 14.801653\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-14.8    \u001b[0m | \u001b[0m 0.8325  \u001b[0m | \u001b[0m 0.5924  \u001b[0m | \u001b[0m 0.6191  \u001b[0m | \u001b[0m 2.544   \u001b[0m | \u001b[0m 8.029   \u001b[0m | \u001b[0m 30.61   \u001b[0m | \u001b[0m 0.04131 \u001b[0m | \u001b[0m 28.98   \u001b[0m |\n",
      "cv 14.805716\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-14.81   \u001b[0m | \u001b[0m 0.9395  \u001b[0m | \u001b[0m 0.4628  \u001b[0m | \u001b[0m 3.61    \u001b[0m | \u001b[0m 2.599   \u001b[0m | \u001b[0m 8.868   \u001b[0m | \u001b[0m 43.51   \u001b[0m | \u001b[0m 0.00216 \u001b[0m | \u001b[0m 49.92   \u001b[0m |\n",
      "cv 14.777235\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-14.78   \u001b[0m | \u001b[0m 0.946   \u001b[0m | \u001b[0m 0.2373  \u001b[0m | \u001b[0m 2.605   \u001b[0m | \u001b[0m 0.163   \u001b[0m | \u001b[0m 4.998   \u001b[0m | \u001b[0m 5.833   \u001b[0m | \u001b[0m 0.07958 \u001b[0m | \u001b[0m 40.12   \u001b[0m |\n",
      "cv 14.815971\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-14.82   \u001b[0m | \u001b[0m 0.8691  \u001b[0m | \u001b[0m 0.8425  \u001b[0m | \u001b[0m 3.522   \u001b[0m | \u001b[0m 0.09552 \u001b[0m | \u001b[0m 4.822   \u001b[0m | \u001b[0m 32.97   \u001b[0m | \u001b[0m 0.05815 \u001b[0m | \u001b[0m 41.13   \u001b[0m |\n",
      "cv 14.804919\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-14.8    \u001b[0m | \u001b[0m 0.9868  \u001b[0m | \u001b[0m 0.5912  \u001b[0m | \u001b[0m 2.678   \u001b[0m | \u001b[0m 1.77    \u001b[0m | \u001b[0m 7.643   \u001b[0m | \u001b[0m 19.04   \u001b[0m | \u001b[0m 0.04042 \u001b[0m | \u001b[0m 39.11   \u001b[0m |\n",
      "cv 14.810214\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-14.81   \u001b[0m | \u001b[0m 0.8372  \u001b[0m | \u001b[0m 0.8555  \u001b[0m | \u001b[0m 3.698   \u001b[0m | \u001b[0m 1.471   \u001b[0m | \u001b[0m 5.135   \u001b[0m | \u001b[0m 16.45   \u001b[0m | \u001b[0m 0.006745\u001b[0m | \u001b[0m 55.28   \u001b[0m |\n",
      "cv 14.794951\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.8624  \u001b[0m | \u001b[0m 0.6571  \u001b[0m | \u001b[0m 1.889   \u001b[0m | \u001b[0m 0.5388  \u001b[0m | \u001b[0m 4.123   \u001b[0m | \u001b[0m 8.026   \u001b[0m | \u001b[0m 0.06826 \u001b[0m | \u001b[0m 56.67   \u001b[0m |\n",
      "cv 14.823944\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-14.82   \u001b[0m | \u001b[0m 0.9073  \u001b[0m | \u001b[0m 0.8173  \u001b[0m | \u001b[0m 4.952   \u001b[0m | \u001b[0m 0.6507  \u001b[0m | \u001b[0m 7.309   \u001b[0m | \u001b[0m 16.85   \u001b[0m | \u001b[0m 0.003044\u001b[0m | \u001b[0m 78.6    \u001b[0m |\n",
      "cv 14.796884\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-14.8    \u001b[0m | \u001b[0m 0.864   \u001b[0m | \u001b[0m 0.4068  \u001b[0m | \u001b[0m 2.942   \u001b[0m | \u001b[0m 2.493   \u001b[0m | \u001b[0m 7.139   \u001b[0m | \u001b[0m 44.27   \u001b[0m | \u001b[0m 0.02808 \u001b[0m | \u001b[0m 81.46   \u001b[0m |\n",
      "cv 14.816834\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-14.82   \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 0.8622  \u001b[0m | \u001b[0m 3.437   \u001b[0m | \u001b[0m 0.6465  \u001b[0m | \u001b[0m 8.727   \u001b[0m | \u001b[0m 37.89   \u001b[0m | \u001b[0m 0.02614 \u001b[0m | \u001b[0m 39.36   \u001b[0m |\n",
      "cv 14.775754\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-14.78   \u001b[0m | \u001b[0m 0.9036  \u001b[0m | \u001b[0m 0.1205  \u001b[0m | \u001b[0m 1.037   \u001b[0m | \u001b[0m 1.274   \u001b[0m | \u001b[0m 5.867   \u001b[0m | \u001b[0m 25.86   \u001b[0m | \u001b[0m 0.02849 \u001b[0m | \u001b[0m 66.25   \u001b[0m |\n",
      "cv 14.780694\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-14.78   \u001b[0m | \u001b[0m 0.9728  \u001b[0m | \u001b[0m 0.194   \u001b[0m | \u001b[0m 2.587   \u001b[0m | \u001b[0m 0.3962  \u001b[0m | \u001b[0m 7.577   \u001b[0m | \u001b[0m 22.82   \u001b[0m | \u001b[0m 0.05698 \u001b[0m | \u001b[0m 37.2    \u001b[0m |\n",
      "cv 14.792374\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.829   \u001b[0m | \u001b[0m 0.4904  \u001b[0m | \u001b[0m 1.778   \u001b[0m | \u001b[0m 2.821   \u001b[0m | \u001b[0m 7.819   \u001b[0m | \u001b[0m 38.69   \u001b[0m | \u001b[0m 0.09047 \u001b[0m | \u001b[0m 30.01   \u001b[0m |\n",
      "cv 14.789215\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.9104  \u001b[0m | \u001b[0m 0.5676  \u001b[0m | \u001b[0m 4.81    \u001b[0m | \u001b[0m 0.8764  \u001b[0m | \u001b[0m 5.202   \u001b[0m | \u001b[0m 9.513   \u001b[0m | \u001b[0m 0.002627\u001b[0m | \u001b[0m 90.93   \u001b[0m |\n",
      "cv 14.792034\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.934   \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 1.409   \u001b[0m | \u001b[0m 1.759   \u001b[0m | \u001b[0m 4.319   \u001b[0m | \u001b[0m 26.85   \u001b[0m | \u001b[0m 0.09777 \u001b[0m | \u001b[0m 87.11   \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=6, n_estimators=10000, learning_rate=0.001, output_process=False):\n",
    "    # prepare data\n",
    "    train = X\n",
    "    #train_data = lgb.Dataset(data=X, label=y, categorical_feature = None, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "        train_results = np.zeros(train.shape[0])\n",
    "        kfolds = KFold(random_state=2019,n_splits=5,shuffle=True)\n",
    "        for train_index,valid_index in kfolds.split(train):\n",
    "\n",
    "            x_train = train.loc[train_index,:]\n",
    "            y_train = y[train_index].values\n",
    "            x_valid = train.loc[valid_index,:]\n",
    "            y_valid = y[valid_index].values\n",
    "            d_train = lgb.Dataset(x_train,\n",
    "                              label=y_train)\n",
    "            d_valid = lgb.Dataset(x_valid,\n",
    "                              label=y_valid)\n",
    "            params = {'objective':'mae','num_iterations': n_estimators, 'learning_rate':learning_rate, \n",
    "                      'early_stopping_round':200, 'metric':'l1'}\n",
    "            params[\"num_leaves\"] = int(round(num_leaves))\n",
    "            params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "            params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "            params['max_depth'] = int(round(max_depth))\n",
    "            params['lambda_l1'] = max(lambda_l1, 0)\n",
    "            params['lambda_l2'] = max(lambda_l2, 0)\n",
    "            params['min_split_gain'] = min_split_gain\n",
    "            params['min_child_weight'] = min_child_weight\n",
    "            bst = lgb.train(params=params, train_set=d_train,valid_sets=[d_valid],verbose_eval=False,early_stopping_rounds=200)\n",
    "            train_results[valid_index] = bst.predict(x_valid)\n",
    "        cv_result = mae(train_results,y.values)\n",
    "        print('cv %f'%cv_result)\n",
    "        #cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, verbose_eval = 200, metrics=['l1'])\n",
    "        return -cv_result\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 96),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (4, 8.99),\n",
    "                                            'lambda_l1': (0, 5),\n",
    "                                            'lambda_l2': (0, 3),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (5, 50)}, random_state=0)\n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    " # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.max['params']\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(train.loc[:,predictor], train.loc[:,'grades'], init_round=5, opt_round=30, n_folds=5, random_seed=6, n_estimators=2000, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 1.0,\n",
       " 'feature_fraction': 0.9,\n",
       " 'lambda_l1': 5.0,\n",
       " 'lambda_l2': 3.0,\n",
       " 'max_depth': 4.0,\n",
       " 'min_child_weight': 39.04831824235355,\n",
       " 'min_split_gain': 0.1,\n",
       " 'num_leaves': 58.2848541708953}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
